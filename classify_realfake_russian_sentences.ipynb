{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classify_realfake_russian_sentences.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN2mZc2uwMkaYe8k+iVRd2z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pandaklez/NLP/blob/master/classify_realfake_russian_sentences.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqUmhe6lm4t6",
        "outputId": "24ed60b3-95ca-471b-ce4b-e91eb47e6ade"
      },
      "source": [
        "!pip install razdel"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting razdel\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: razdel\n",
            "Successfully installed razdel-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-6C5fnboQtm",
        "outputId": "a3368787-6323-4f15-9f68-111d3a5ed5a1"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQiYNIs1XJav"
      },
      "source": [
        "from string import punctuation\n",
        "from collections import Counter, defaultdict\n",
        "from razdel import sentenize\n",
        "from razdel import tokenize as razdel_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import numpy as np\n",
        "\n",
        "def normalize(text):\n",
        "    normalized_text = [word.text.strip(punctuation) for word \\\n",
        "                                                            in razdel_tokenize(text)]\n",
        "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
        "    return normalized_text"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ1v6cAQm088",
        "outputId": "9d300c9f-f321-43a6-ba04-0834552ec859"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/lenta.txt.zip -O lenta.txt.zip\n",
        "!unzip lenta.txt.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-06 12:02:38--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/lenta.txt.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5723675 (5.5M) [application/zip]\n",
            "Saving to: ‘lenta.txt.zip’\n",
            "\n",
            "lenta.txt.zip       100%[===================>]   5.46M  28.3MB/s    in 0.2s    \n",
            "\n",
            "2021-08-06 12:02:38 (28.3 MB/s) - ‘lenta.txt.zip’ saved [5723675/5723675]\n",
            "\n",
            "Archive:  lenta.txt.zip\n",
            "replace lenta.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: lenta.txt               \n",
            "replace __MACOSX/._lenta.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/._lenta.txt    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I82c4DJIi9t",
        "outputId": "e7880019-21b4-464a-91f0-c5ca7ee8742a"
      },
      "source": [
        "#!wget https://ruscorpora.ru/new/ngrams/3grams-3.zip -O 3grams-3.zip\n",
        "#!unzip 3grams-3.zip"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-06 11:04:24--  https://ruscorpora.ru/new/ngrams/3grams-3.zip\n",
            "Resolving ruscorpora.ru (ruscorpora.ru)... 82.148.12.99\n",
            "Connecting to ruscorpora.ru (ruscorpora.ru)|82.148.12.99|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 32452212 (31M) [application/zip]\n",
            "Saving to: ‘3grams-3.zip’\n",
            "\n",
            "3grams-3.zip        100%[===================>]  30.95M  7.26MB/s    in 4.3s    \n",
            "\n",
            "2021-08-06 11:04:29 (7.26 MB/s) - ‘3grams-3.zip’ saved [32452212/32452212]\n",
            "\n",
            "Archive:  3grams-3.zip\n",
            "  inflating: 3grams-3.txt            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh_umq5LvDyY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HbPNf7bIsUS",
        "outputId": "62d33f30-82d7-4d9b-c583-8d66cbb9f42c"
      },
      "source": [
        "!ls -lsha"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 215M\n",
            "4.0K drwxr-xr-x 1 root root 4.0K Aug  6 11:15 .\n",
            "4.0K drwxr-xr-x 1 root root 4.0K Aug  6 10:37 ..\n",
            "158M -rw-r--r-- 1 root root 158M Nov  1  2011 3grams-3.txt\n",
            " 31M -rw-r--r-- 1 root root  31M Aug  3 17:55 3grams-3.zip\n",
            "4.0K drwxr-xr-x 4 root root 4.0K Jul 16 13:19 .config\n",
            " 21M -rw-r--r-- 1 root root  21M Nov 15  2020 lenta.txt\n",
            "5.5M -rw-r--r-- 1 root root 5.5M Aug  6 11:15 lenta.txt.zip\n",
            "4.0K drwxr-xr-x 2 root root 4.0K Aug  6 11:15 __MACOSX\n",
            "4.0K drwxr-xr-x 1 root root 4.0K Jul 16 13:20 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP5BXXSzIsdK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeO5L2uCnUyX"
      },
      "source": [
        "with open('lenta.txt', 'r', encoding='utf-8') as f:\n",
        "    lenta = f.read()\n",
        "\n",
        "#lenta = lenta[:50000]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "cjNhAhWLHnXK",
        "outputId": "ed02713c-0e49-4e15-caeb-1d78b7d4311f"
      },
      "source": [
        "len(lenta)\n",
        "lenta[:500]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Бои у Сопоцкина и Друскеник закончились отступлением германцев. Неприятель, приблизившись с севера к Осовцу начал артиллерийскую борьбу с крепостью. В артиллерийском бою принимают участие тяжелые калибры. С раннего утра 14 сентября огонь достиг значительного напряжения. Попытка германской пехоты пробиться ближе к крепости отражена. В Галиции мы заняли Дембицу. Большая колонна, отступавшая по шоссе от Перемышля к Саноку, обстреливалась с высот нашей батареей и бежала, бросив парки, обоз и автомоб'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAzCCgzDuEF3",
        "outputId": "67dcef11-53ba-45be-e416-6eb9dd00673c"
      },
      "source": [
        "# количество токенов в корпусе\n",
        "len(normalize(lenta))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1505789"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gunPzHAGvidD"
      },
      "source": [
        "Мы хотим сделать корпус на 10 миллионов слов.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYtyz16vwr86"
      },
      "source": [
        "with open('mal_hik_so_spagoi.txt', 'r', encoding='utf-8') as f:\n",
        "    spaga = f.read()\n",
        "\n",
        "with open('nabokov.txt', 'r', encoding='utf-8') as f:\n",
        "    nabokov = f.read()\n",
        "\n",
        "with open('wiki_data.txt', 'r', encoding='utf-8') as f:\n",
        "  wiki = f.read()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtVjmxxuxs1O"
      },
      "source": [
        "all_texts = lenta + '\\n' + spaga + '\\n' + nabokov + '\\n' + wiki"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bub1REHEx3Xs",
        "outputId": "1103f11c-95fb-4035-b49f-92ef2684a1e4"
      },
      "source": [
        "len(normalize(all_texts))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7087345"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AutauhTTnhp4"
      },
      "source": [
        "Вот мы прочитали данные (новостные тексты ленты), теперь мы можем сделать фейковые предложения на русском языке, например, на триграммах"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9ZwaQa9ngvk"
      },
      "source": [
        "def ngrammer(tokens, n=3):\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams\n",
        "\n",
        "def create_ngrams(sentences):\n",
        "    unigrams, bigrams, trigrams = Counter(), Counter(), Counter()\n",
        "    for sentence in sentences:\n",
        "        unigrams.update(sentence)\n",
        "        bigrams.update(ngrammer(sentence, n=2))\n",
        "        trigrams.update(ngrammer(sentence, n=3))\n",
        "    return unigrams, bigrams, trigrams"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xsAoeYLoCAG"
      },
      "source": [
        "sentences_news = [ ['<start>'] + ['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(all_texts)]\n",
        "\n",
        "unigrams_news, bigrams_news, trigrams_news = create_ngrams(sentences_news)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiqkRZdWH54l",
        "outputId": "05485f3c-a756-444e-de94-b74c13c4cd0c"
      },
      "source": [
        "len(sentences_news)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "305528"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UevsP4BXobee"
      },
      "source": [
        "def create_matrix_old(unigrams, bigrams, trigrams):\n",
        "    matrix_trigrams = np.zeros((len(bigrams), len(unigrams)))\n",
        "    matrix_bigrams = np.zeros((len(unigrams), len(unigrams)))\n",
        "    id2bigram = list(bigrams)\n",
        "    bigram2id  =  {bigram:i for i, bigram in enumerate(id2bigram)}\n",
        "    id2word = list(unigrams)\n",
        "    word2id = {word:i for i, word in enumerate(id2word)}\n",
        "    for ngram in trigrams:\n",
        "        ngram_ = ngram.split(' ')\n",
        "        bigram, unigram = ' '.join(ngram_[:-1]), ngram_[-1]\n",
        "        matrix_trigrams[bigram2id[bigram]][word2id[unigram]] =  (trigrams[ngram] / bigrams[bigram])\n",
        "    for ngram in bigrams:\n",
        "        word1, word2 = ngram.split(' ')\n",
        "        matrix_bigrams[word2id[word1]][word2id[word2]] =  (bigrams[ngram] / unigrams[word1])\n",
        "    return matrix_trigrams, matrix_bigrams, id2bigram, bigram2id, id2word, word2id"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8pyGC5_R2A0",
        "outputId": "4e0a57c7-b904-4607-e128-cfb576eea735"
      },
      "source": [
        "list(trigrams_news)[:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> <start> бои',\n",
              " '<start> бои у',\n",
              " 'бои у сопоцкина',\n",
              " 'у сопоцкина и',\n",
              " 'сопоцкина и друскеник']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGZVpaHFSJ5z",
        "outputId": "fede0d43-cd39-4423-c684-059c4a92b780"
      },
      "source": [
        "# bigram2id_news\n",
        "{bigram:i for i, bigram in enumerate(list(bigrams_news)[:10])}"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<start> <start>': 0,\n",
              " '<start> бои': 1,\n",
              " 'бои у': 2,\n",
              " 'германцев <end>': 9,\n",
              " 'друскеник закончились': 6,\n",
              " 'закончились отступлением': 7,\n",
              " 'и друскеник': 5,\n",
              " 'отступлением германцев': 8,\n",
              " 'сопоцкина и': 4,\n",
              " 'у сопоцкина': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06ukcq7JUdfc",
        "outputId": "28b3a48e-4c5b-4be2-90e7-005f102f8843"
      },
      "source": [
        "trigrams_news['30 раненых в']/bigrams_news['30 раненых']"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM98YGYjOyFI"
      },
      "source": [
        "def create_matrix(unigrams, bigrams, trigrams):\n",
        "    # matrix_trigrams = np.zeros((len(bigrams), len(unigrams)))\n",
        "    # matrix_bigrams = np.zeros((len(unigrams), len(unigrams)))\n",
        "    dict_trigrams = defaultdict(int)\n",
        "\n",
        "    id2bigram = list(bigrams)\n",
        "    bigram2id  =  {bigram:i for i, bigram in enumerate(id2bigram)}\n",
        "    id2word = list(unigrams)\n",
        "    word2id = {word:i for i, word in enumerate(id2word)}\n",
        "    for ngram in trigrams:\n",
        "        ngram_ = ngram.split(' ')\n",
        "        bigram, unigram = ' '.join(ngram_[:-1]), ngram_[-1]\n",
        "        # bigram бои у || unigram сопоцкина\n",
        "        # matrix_trigrams[bigram2id[bigram]][word2id[unigram]] =  (trigrams[ngram] / bigrams[bigram])\n",
        "        dict_trigrams[bigram + '_' + unigram] = (trigrams[ngram] / bigrams[bigram])\n",
        "    #for ngram in bigrams:\n",
        "    #    word1, word2 = ngram.split(' ')\n",
        "    #    matrix_bigrams[word2id[word1]][word2id[word2]] =  (bigrams[ngram] / unigrams[word1])\n",
        "    return dict_trigrams, id2bigram, bigram2id, id2word, word2id  # matrix_bigrams"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElWdCTacobiI"
      },
      "source": [
        "dict_trigrams_news, id2bigram_news, bigram2id_news, id2word_news, word2id_news = create_matrix(unigrams_news, bigrams_news, trigrams_news)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KP0lxU0l6ji"
      },
      "source": [
        "dict_trigrams_news"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BG9Y928YW0cx",
        "outputId": "12005b57-4246-46b9-83aa-364d3e512e91"
      },
      "source": [
        "'<start> <start>' + '_' + 'агентство' in dict_trigrams_news.keys()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_dhZnfe_mhN8",
        "outputId": "da4b2edf-207b-4df6-fc49-6a438d25f30b"
      },
      "source": [
        "# list of unigrams\n",
        "id2word_news[3]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'сопоцкина'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGa74rFpnh2L"
      },
      "source": [
        "id2bigram_news"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFDwhctxpLUc"
      },
      "source": [
        "def trigrams_generator_old(matrix, id2word, ngram2id, id2ngram, n=100, start='<start> <start>'):\n",
        "    text = []\n",
        "    current_idx = ngram2id[start]\n",
        "    for i in range(n):\n",
        "        chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
        "        text.append(id2word[chosen])\n",
        "        if id2word[chosen] == '<end>':\n",
        "            token = start\n",
        "        else:\n",
        "            token = id2ngram[current_idx].split()[-1] + \" \" + id2word[chosen]\n",
        "        current_idx = ngram2id[token]\n",
        "    return ' '.join(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFFgJ5Dgom2g"
      },
      "source": [
        "def trigrams_generator(dict_grams, id2word, ngram2id, id2ngram, n=30, start='<start> <start>'):\n",
        "    text = []\n",
        "    current_idx = ngram2id[start]\n",
        "    current_token = start\n",
        "\n",
        "    for i in range(n):\n",
        "        # chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
        "        probs = [dict_grams[current_token + '_' + word] if current_token + '_' + word in dict_grams.keys() else 0.0 for word in id2word]\n",
        "        chosen = np.random.choice(len(id2word), p=probs)\n",
        "        text.append(id2word[chosen])\n",
        "        if id2word[chosen] == '<end>':\n",
        "            current_token = start\n",
        "        else:\n",
        "            # get current bigram, get last word of current bigram, glue last word of bigram + chosen token\n",
        "            current_token = id2ngram[current_idx].split()[-1] + \" \" + id2word[chosen]\n",
        "        current_idx = ngram2id[current_token]\n",
        "    return ' '.join(text)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyLuq6neopzn",
        "outputId": "d04bc111-b962-4afa-a7b3-78fa8fef7a2e"
      },
      "source": [
        "from pprint import pprint\n",
        "\n",
        "print(trigrams_generator(dict_grams=dict_trigrams_news, id2word=id2word_news, ngram2id=bigram2id_news, id2ngram=id2bigram_news).replace('<end>', '\\n'))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "философское антиковедение и классическая музыка пение плавание чтение биографической и исторической лингвистики леману принадлежит заслуга основания двух кафедр в техасском университете \n",
            " перси аннабет \n",
            " также лемоннье в чём не\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKNGJR2CpTs6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}